{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "print(torch.__version__)\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# import matplotlib\n",
    "# %matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "from dataloaders import fundus_dataloader as DL\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloaders import custom_transforms as tr\n",
    "from torchvision import transforms\n",
    "# from scipy.misc import imsave\n",
    "from matplotlib.pyplot import imsave\n",
    "from utils.Utils import *\n",
    "from utils.metrics import *\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import networks.deeplabv3 as netd\n",
    "import networks.deeplabv3_eval as netd_eval\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSNE\n",
    "def compute_tsne(concat_feats):\n",
    "    # Define the number of dimensions to reduce to (usually 2 for visualization)\n",
    "    n_components = 2\n",
    "\n",
    "    # Create a TSNE object with desired parameters (optional)\n",
    "    tsne = TSNE(n_components=n_components)  # You can adjust perplexity for better embedding\n",
    "\n",
    "    # new_feats = concat_feats\n",
    "    #\n",
    "    # new_feats = (concat_feats - concat_feats.min(axis=0)) - (concat_feats.max() - concat_feats.min()) \n",
    "\n",
    "    # new_feats = concat_feats - concat_feats.max\n",
    "    # Apply t-SNE to the features\n",
    "    transformed_features_retry = tsne.fit_transform(concat_feats)\n",
    "    \n",
    "    return transformed_features_retry\n",
    "\n",
    "def  show_tsne_plot(tsne_feats, concat_labels, num_prototypes = 0):\n",
    "    from matplotlib import pyplot as plt\n",
    "    # Optional: Set plot styles\n",
    "    plt.style.use(\"ggplot\")\n",
    "\n",
    "    # Create the scatter plot with color-coded target labels (if applicable)\n",
    "    # if target is not None:\n",
    "    #   plt.scatter(transformed_features[:, 0], transformed_features[:, 1], c=target)\n",
    "    # else:\n",
    "    print(tsne_feats[:, 0].shape)\n",
    "    print(tsne_feats[:, 1].shape)\n",
    "    print(\"###########\")\n",
    "    print(np.isnan(tsne_feats[:5, 0]).any())\n",
    "    print(np.isnan(tsne_feats[:5, 1]).any())\n",
    "\n",
    "    # Label the axes\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(\"t-SNE Visualization of Features\")\n",
    "\n",
    "    # plt.scatter(tsne_feats[:-5, 0], tsne_feats[:-5, 1], c=concat_labels[:,:-5])\n",
    "    \n",
    "    if num_prototypes > 0:\n",
    "        minus_proto = -1 * num_prototypes\n",
    "        print(minus_proto)\n",
    "        print(concat_labels[minus_proto:])\n",
    "        plt.scatter(tsne_feats[:minus_proto, 0], tsne_feats[:minus_proto, 1], c=concat_labels[:minus_proto]), \n",
    "        plt.scatter(tsne_feats[minus_proto:, 0], tsne_feats[minus_proto:, 1], c=concat_labels[minus_proto:], marker='*', edgecolors=[\"black\"], s=700)\n",
    "    else:\n",
    "        plt.scatter(tsne_feats[:, 0], tsne_feats[:, 1], c=concat_labels, s=100)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_args = {\n",
    "    'data_dir': '../datasets/Fundus',\n",
    "    'dataset': 'Domain2',\n",
    "    # 'model_file': '/users/scratch/baryaacovi-2024-06-01/projects/SFDA-DPL/base.pth.tar',\n",
    "    # 'model_file': '/users/scratch/baryaacovi-2024-06-01/projects/SFDA-DPL/logs/Domain2/20240717_135233.062115/checkpoint_200.pth.tar',\n",
    "    'out_stride': 16,\n",
    "    'sync_bn': True,\n",
    "    'freeze_bn': False\n",
    "}\n",
    "\n",
    "args_dpl = {\n",
    "    **base_args,\n",
    "    'model_file': '/users/scratch/baryaacovi-2024-06-01/projects/SFDA-DPL/logs/train_target/D2_checkpoint_1.pth.tar',\n",
    "}\n",
    "\n",
    "args_noada = {\n",
    "    **base_args,\n",
    "    # 'dataset': 'Domain2',\n",
    "    'model_file': '/users/scratch/baryaacovi-2024-06-01/projects/SFDA-DPL/base.pth.tar',\n",
    "}\n",
    "\n",
    "data_dir = base_args['data_dir']\n",
    "dataset = base_args['dataset']\n",
    "\n",
    "composed_transforms_train = transforms.Compose([\n",
    "    tr.Resize(512),\n",
    "    tr.add_salt_pepper_noise(),\n",
    "    tr.adjust_light(),\n",
    "    tr.eraser(),\n",
    "    tr.Normalize_tf(),\n",
    "    tr.ToTensor()\n",
    "])\n",
    "composed_transforms_test = transforms.Compose([\n",
    "    tr.Resize(512),\n",
    "    tr.Normalize_tf(),\n",
    "    tr.ToTensor()\n",
    "])\n",
    "\n",
    "print(\"Creating dataloader\")\n",
    "print(\"Train batch size was 8 and changed to 1\")\n",
    "db_train = DL.FundusSegmentation(base_dir=data_dir, dataset=dataset, split='train/ROIs', transform=composed_transforms_test)\n",
    "train_loader = DataLoader(db_train, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "db_test = DL.FundusSegmentation(base_dir=data_dir, dataset=dataset, split='test/ROIs', transform=composed_transforms_test)\n",
    "test_loader = DataLoader(db_test, batch_size=1, shuffle=False, \n",
    "                        num_workers=1\n",
    ")\n",
    "print(\"Dataloader created\")\n",
    "\n",
    "def create_model_from_args(args : dict):\n",
    "    model_file = args['model_file']\n",
    "    out_stride = args['out_stride']\n",
    "    sync_bn = args['sync_bn']\n",
    "    freeze_bn = args['freeze_bn']\n",
    "\n",
    "    print(\"Move model to cuda\")\n",
    "    model = netd_eval.DeepLab(num_classes=2, backbone='mobilenet', output_stride=out_stride, sync_bn=sync_bn, freeze_bn=freeze_bn).cuda()\n",
    "    print(\"Model moved to cuda\")\n",
    "    checkpoint = torch.load(model_file)\n",
    "\n",
    "    pretrained_dict = checkpoint['model_state_dict']\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model.state_dict()}\n",
    "\n",
    "    print(\"Loading model\")\n",
    "    model.load_state_dict(pretrained_dict)\n",
    "    print(\"Model loaded\")\n",
    "    # pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    # model.load_state_dict(pretrained_dict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model_from_args(args_dpl)\n",
    "model_noada = create_model_from_args(args_noada)\n",
    "\n",
    "if args_dpl['dataset']==\"Domain2\":\n",
    "    npfilename = './generate_pseudo/pseudolabel_D2.npz'\n",
    "elif args_dpl['dataset']==\"Domain1\":\n",
    "    npfilename = './generate_pseudo/pseudolabel_D1.npz'\n",
    "\n",
    "npdata = np.load(npfilename, allow_pickle=True)\n",
    "pseudo_label_dic = npdata['arr_0'].item()\n",
    "uncertain_dic = npdata['arr_1'].item()\n",
    "proto_pseudo_dic = npdata['arr_2'].item()\n",
    "\n",
    "model = model_noada\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute model dice on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pseudo_label_dic[list(pseudo_label_dic.keys())[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.train()\n",
    "\n",
    "get_hd = True\n",
    "val_cup_dice = 0.0;val_disc_dice = 0.0;datanum_cnt = 0.0\n",
    "cup_hd = 0.0; disc_hd = 0.0;datanum_cnt_cup = 0.0;datanum_cnt_disc = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (sample) in enumerate(test_loader):\n",
    "        data, target, img_name = sample['image'], sample['map'], sample['img_name']\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        prediction, boundary, _ = model(data)\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "\n",
    "        target_numpy = target.data.cpu()\n",
    "        prediction = prediction.data.cpu()\n",
    "        prediction[prediction>0.75] = 1;prediction[prediction <= 0.75] = 0\n",
    "\n",
    "\n",
    "        cup_dice = dice_coefficient_numpy(prediction[:,0, ...], target_numpy[:, 0, ...])\n",
    "        disc_dice = dice_coefficient_numpy(prediction[:,1, ...], target_numpy[:, 1, ...])\n",
    "\n",
    "        for i in range(prediction.shape[0]):\n",
    "            hd_tmp = hd_numpy(prediction[i, 0, ...], target_numpy[i, 0, ...], get_hd)\n",
    "            if np.isnan(hd_tmp):\n",
    "                datanum_cnt_cup -= 1.0\n",
    "            else:\n",
    "                cup_hd += hd_tmp\n",
    "\n",
    "            hd_tmp = hd_numpy(prediction[i, 1, ...], target_numpy[i, 1, ...], get_hd)\n",
    "            if np.isnan(hd_tmp):\n",
    "                datanum_cnt_disc -= 1.0\n",
    "            else:\n",
    "                disc_hd += hd_tmp\n",
    "\n",
    "        val_cup_dice += np.sum(cup_dice)\n",
    "        val_disc_dice += np.sum(disc_dice)\n",
    "\n",
    "        datanum_cnt += float(prediction.shape[0])\n",
    "        datanum_cnt_cup += float(prediction.shape[0])\n",
    "        datanum_cnt_disc += float(prediction.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cup_dice /= datanum_cnt\n",
    "val_disc_dice /= datanum_cnt\n",
    "cup_hd /= datanum_cnt_cup\n",
    "disc_hd /= datanum_cnt_disc\n",
    "\n",
    "print(\"cup: %.4f disc: %.4f avg: %.4f cup: %.4f disc: %.4f avg: %.4f\" %\n",
    "(val_cup_dice, val_disc_dice, (val_cup_dice+val_disc_dice)/2.0, cup_hd, disc_hd, (cup_hd+disc_hd)/2.0))\n",
    "# print(\"best cup: %.4f best disc: %.4f best avg: %.4f best cup: %.4f best disc: %.4f best avg: %.4f\" %\n",
    "# (best_val_cup_dice, best_val_disc_dice, best_avg, best_cup_hd, best_disc_hd, best_avg_hd))\n",
    "\n",
    "\n",
    "# cup: 0.8773 disc: 0.9537 avg: 0.9155 cup: 6.8760 disc: 7.4139 avg: 7.1449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.shape)\n",
    "\n",
    "# cup_dice = dice_coefficient_numpy(prediction[:,0, ...], target_numpy[:, 0, ...])\n",
    "# disc_dice = dice_coefficient_numpy(prediction[:,1, ...], target_numpy[:, 1, ...])\n",
    "                                   \n",
    "# print(cup_dice)\n",
    "# print(disc_dice)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, target, img_name = sample['image'], sample['map'], sample['img_name']\n",
    "# if torch.cuda.is_available():\n",
    "#     data, target = data.cuda(), target.cuda()\n",
    "# data, target = Variable(data), Variable(target)\n",
    "\n",
    "prediction, boundary, last_conv_feats = model(data)\n",
    "prediction = torch.sigmoid(prediction)\n",
    "\n",
    "target_numpy = target.data.cpu()\n",
    "prediction = prediction.data.cpu()\n",
    "prediction[prediction>0.75] = 1;prediction[prediction <= 0.75] = 0\n",
    "\n",
    "\n",
    "cup_dice = dice_coefficient_numpy(prediction[:,0, ...], target_numpy[:, 0, ...])\n",
    "disc_dice = dice_coefficient_numpy(prediction[:,1, ...], target_numpy[:, 1, ...])\n",
    "\n",
    "# fig,axes = plt.subplots(1,3,figsize=(15,5))\n",
    "print(data.shape)\n",
    "plt.imshow(data[0].cpu().numpy().transpose(1, 2, 0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "model = model.train()\n",
    "\n",
    "def add_mask(img,mask):  \n",
    "    label2color = {0:np.array([0,0,0]),1:np.array([224/255,255/255,255/255])\n",
    "                #    ,2:np.array([240,130,40]),3:np.array([206,242,151]),4:np.array([238,172,255]),5:np.array([0,255,255])\n",
    "                   }\n",
    "    \n",
    "    \n",
    "    # pred_mask = np.zeros_like(img).astype(np.uint8)\n",
    "    pred_mask = np.zeros_like(img).astype(np.float32)\n",
    "    # print(pred_mask.shape)\n",
    "    # print(mask.shape)\n",
    "    for l,color in label2color.items():\n",
    "        # print(pred_mask[:, mask==l].shape)\n",
    "        # print((mask==l).shape)\n",
    "        pred_mask[:, mask==l] = np.expand_dims(color,1)\n",
    "    img_pred = cv2.addWeighted(img,0.5,pred_mask,0.5,0,0)\n",
    "    return img_pred\n",
    "\n",
    "def add_mask_outline(img, mask, gt):\n",
    "    label2color = {0:np.array([0,0,0]),1:np.array([224/255,255/255,255/255])\n",
    "                #    ,2:np.array([240,130,40]),3:np.array([206,242,151]),4:np.array([238,172,255]),5:np.array([0,255,255])\n",
    "    }\n",
    "    mask = mask.astype(np.uint8)\n",
    "    gt = gt.astype(np.uint8)\n",
    "    img = (img * 255).astype(np.uint8).copy()\n",
    "    \n",
    "    colors = [(3, 94, 252), (3, 252, 32)]\n",
    "    masks = [mask, gt]\n",
    "    \n",
    "    for color, mask in zip(colors, masks):\n",
    "        cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        for c in cnts:\n",
    "            cv2.drawContours(img, [c], -1, color, thickness=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def add_heatmap(img,entropy_map):\n",
    "\n",
    "    entropy_map = (entropy_map - entropy_map.min())/(entropy_map.max()-entropy_map.min())\n",
    "    entropy_map = (entropy_map * 255).astype(np.uint8)\n",
    "    print(entropy_map.dtype)\n",
    "    print(img.dtype)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(entropy_map[0],cv2.COLORMAP_JET)\n",
    "    img_uncertainty = cv2.addWeighted(img,0.7,heatmap[:,:,::-1],0.3,0,0)\n",
    "    return img_uncertainty\n",
    "\n",
    "def create_visuals(inspect_dict, data, target, img_name, prediction, target_numpy, cup_dice, disc_dice, entropy_map):\n",
    "    classes = [0,1]\n",
    "    classes_names = ['cup', 'disc']\n",
    "    dice_scores = [cup_dice, disc_dice]\n",
    "    print(f\"IMG: {img_name} CUP_DICE: {cup_dice} DISC_DICE: {disc_dice[0]}\")\n",
    "    show_images = []\n",
    "    view_img = make_grid(\n",
    "                        data[0, ...].clone().cpu().data, 1, normalize=True).detach().cpu().numpy()\n",
    "    show_images.append(view_img.transpose(1,2,0))\n",
    "    for name,class_id,dice_score in zip(classes_names, classes, dice_scores):\n",
    "                # print(data.detach().cpu().numpy()[0].shape)\n",
    "                # print(f\"max data {data.max()} min data {data.min()}\")\n",
    "                \n",
    "                # print(view_img.dtype)\n",
    "        gt_mask = target_numpy.detach().cpu().numpy()[:,class_id, ...].transpose(1, 2, 0)\n",
    "        pred_mask = prediction.detach().cpu().numpy()[:,class_id, ...].transpose(1, 2, 0)\n",
    "                # print(view_img.shape)\n",
    "                # print(gt_mask.shape)                \n",
    "        masked_im = add_mask_outline(view_img.transpose(1,2,0), gt_mask[:,:,0], pred_mask[:,:,0])\n",
    "                # masked_pred = add_mask_outline(view_img.transpose(1,2,0), pred_mask[:,:,0])\n",
    "        show_images.append(masked_im)\n",
    "    \n",
    "    print(f\"View img shape: {view_img.shape}\")\n",
    "    print(f\"Entropy map shape: {entropy_map.shape}\")\n",
    "    entropy_img = add_heatmap(view_img.transpose(1,2,0), entropy_map.detach().cpu().numpy())\n",
    "    \n",
    "    fig,axes = plt.subplots(1,4,figsize=(22,6))\n",
    "            \n",
    "    fig.suptitle(f\"Image: {img_name[0]} | {classes_names[0]} dice: {round(cup_dice[0], 4) * 100} | {classes_names[1]} dice: {round(disc_dice[0], 4) * 100}\")\n",
    "    green_patch = mpatches.Patch(color='green', label='Prediction')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Ground Truth')\n",
    "    fig.legend(handles=[green_patch, blue_patch])\n",
    "            \n",
    "    axes[0].title.set_text(\"Original Image\")\n",
    "    axes[0].imshow(view_img.transpose(1,2,0))\n",
    "    axes[1].title.set_text(\"Cup\")\n",
    "    axes[1].imshow(show_images[1])\n",
    "    axes[2].imshow(prediction.detach().cpu().numpy()[:,0, ...].transpose(1, 2, 0))\n",
    "    axes[2].title.set_text(\"Disc\")\n",
    "    axes[2].imshow(show_images[2])\n",
    "    axes[3].title.set_text(\"Entropy\")\n",
    "    axes[3].imshow(entropy_img)\n",
    "\n",
    "    inspect_dict[img_name[0]] = (data, target, img_name)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "get_hd = True\n",
    "val_cup_dice = 0.0;val_disc_dice = 0.0;datanum_cnt = 0.0\n",
    "cup_hd = 0.0; disc_hd = 0.0;datanum_cnt_cup = 0.0;datanum_cnt_disc = 0.0\n",
    "cnt_low_dice = 0.0\n",
    "inspect_dict = {}\n",
    "\n",
    "bar_pseudo_path = '/users/scratch/baryaacovi-2024-06-01/projects/SFDA-DPL/results/prototype/pseudolabel_D2_bar.npz'\n",
    "bar_pseudo = np.load(bar_pseudo_path, allow_pickle=True)\n",
    "show_counter = 0 \n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (sample) in enumerate(train_loader):\n",
    "        data, target, img_name = sample['image'], sample['map'], sample['img_name']\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        prediction, boundary, _ = model(data)\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "\n",
    "        target_numpy = target.data.cpu()\n",
    "        prediction = prediction.data.cpu()\n",
    "        probs = prediction.clone()\n",
    "        prediction[prediction>0.75] = 1;prediction[prediction <= 0.75] = 0\n",
    "\n",
    "\n",
    "        cup_dice = dice_coefficient_numpy(prediction[:,0, ...], target_numpy[:, 0, ...])\n",
    "        disc_dice = dice_coefficient_numpy(prediction[:,1, ...], target_numpy[:, 1, ...])\n",
    "\n",
    "        # print(\"cup_dice: \", cup_dice)\n",
    "        # print(\"disc_dice: \", disc_dice)\n",
    "        print(cup_dice)\n",
    "        print(\"Probs: \", probs.shape)\n",
    "        entropy_map = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)\n",
    "        if show_counter <= 2:\n",
    "            create_visuals(inspect_dict, data, target, img_name, prediction, target_numpy, cup_dice, disc_dice, entropy_map)\n",
    "            cnt_low_dice += prediction.shape[0]\n",
    "            show_counter += 1\n",
    "        # break\n",
    "        # if cup_dice <0.65:\n",
    "        #     if img_name == 'G-22-L.png':\n",
    "        #         continue\n",
    "        #     print(\"Probs: \", probs.shape)\n",
    "        #     entropy_map = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)\n",
    "        #     create_visuals(inspect_dict, data, target, img_name, prediction, target_numpy, cup_dice, disc_dice, entropy_map)\n",
    "        #     cnt_low_dice += prediction.shape[0]\n",
    "        #     break\n",
    "            \n",
    "        for i in range(prediction.shape[0]):\n",
    "            hd_tmp = hd_numpy(prediction[i, 0, ...], target_numpy[i, 0, ...], get_hd)\n",
    "            if np.isnan(hd_tmp):\n",
    "                datanum_cnt_cup -= 1.0\n",
    "            else:\n",
    "                cup_hd += hd_tmp\n",
    "\n",
    "            hd_tmp = hd_numpy(prediction[i, 1, ...], target_numpy[i, 1, ...], get_hd)\n",
    "            if np.isnan(hd_tmp):\n",
    "                datanum_cnt_disc -= 1.0\n",
    "            else:\n",
    "                disc_hd += hd_tmp\n",
    "\n",
    "        val_cup_dice += np.sum(cup_dice)\n",
    "        val_disc_dice += np.sum(disc_dice)\n",
    "\n",
    "        datanum_cnt += float(prediction.shape[0])\n",
    "        datanum_cnt_cup += float(prediction.shape[0])\n",
    "        datanum_cnt_disc += float(prediction.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect_dict.keys())          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = list(inspect_dict.keys())[0]\n",
    "print(f\"Working on {img_name}...\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "data, target = Variable(data), Variable(target)\n",
    "prediction, boundary, last_layer_feats = model(data)\n",
    "prediction = torch.sigmoid(prediction)\n",
    "\n",
    "target_numpy = target.data.cpu()\n",
    "prediction = prediction.data.cpu()\n",
    "prediction[prediction>0.75] = 1;prediction[prediction <= 0.75] = 0\n",
    "\n",
    "\n",
    "cup_dice = dice_coefficient_numpy(prediction[:,0, ...], target_numpy[:, 0, ...])\n",
    "disc_dice = dice_coefficient_numpy(prediction[:,1, ...], target_numpy[:, 1, ...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cup_dice /= datanum_cnt\n",
    "val_disc_dice /= datanum_cnt\n",
    "cup_hd /= datanum_cnt_cup\n",
    "disc_hd /= datanum_cnt_disc\n",
    "\n",
    "print(\"cup: %.4f disc: %.4f avg: %.4f cup: %.4f disc: %.4f avg: %.4f\" %\n",
    "(val_cup_dice, val_disc_dice, (val_cup_dice+val_disc_dice)/2.0, cup_hd, disc_hd, (cup_hd+disc_hd)/2.0))\n",
    "# print(\"best cup: %.4f best disc: %.4f best avg: %.4f best cup: %.4f best disc: %.4f best avg: %.4f\" %\n",
    "# (best_val_cup_dice, best_val_disc_dice, best_avg, best_cup_hd, best_disc_hd, best_avg_hd))\n",
    "\n",
    "print(\"num of low dice: \", cnt_low_dice)\n",
    "print(\"num of total images: \", datanum_cnt_cup)\n",
    "\n",
    "# cup: 0.8773 disc: 0.9537 avg: 0.9155 cup: 6.8760 disc: 7.4139 avg: 7.1449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_numpy.shape)\n",
    "\n",
    "def get_combined_mask(target_numpy: np.ndarray):\n",
    "    \n",
    "    tmp = target_numpy.squeeze()\n",
    "\n",
    "    combined_mask = torch.zeros_like(tmp[0])\n",
    "    for i in range(tmp.shape[0]):\n",
    "        combined_mask[torch.logical_and(tmp[i] == True ,combined_mask == False)] = i + 1\n",
    "\n",
    "    # print(combined_mask.max()) \n",
    "    # print(combined_mask.min()) \n",
    "    # print(combined_mask.unique()) \n",
    "    return combined_mask\n",
    "\n",
    "combined_mask = get_combined_mask(target_numpy)\n",
    "concat_labels = torch.flatten(combined_mask)\n",
    "print(concat_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_preprocess = torch.nn.Sequential(model.decoder.last_conv[0:3])\n",
    "features_before_last_conv = last_conv_preprocess(last_layer_feats)\n",
    "print(last_conv_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction.shape)\n",
    "\n",
    "interpolated_feats = F.interpolate(features_before_last_conv, size=data.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "print(interpolated_feats.shape)\n",
    "\n",
    "\n",
    "tsne_feats = torch.flatten(interpolated_feats.squeeze(), 1)\n",
    "\n",
    "one_feats = tsne_feats[:, concat_labels == 1][:,]\n",
    "two_feats = tsne_feats[:, concat_labels == 2][:,]\n",
    "zero_feats = tsne_feats[:, concat_labels == 0][:,:0]\n",
    "\n",
    "reduced_feats = torch.cat((one_feats, two_feats, zero_feats), 1)\n",
    "\n",
    "print(one_feats.shape)\n",
    "print(two_feats.shape)\n",
    "print(reduced_feats.shape)\n",
    "print(tsne_feats.shape)\n",
    "\n",
    "# tsne_output = compute_tsne(reduced_feats.cpu().detach().transpose(0,1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_labels_plot = [1]* one_feats.shape[1] + [2]*two_feats.shape[1] + [0]*zero_feats.shape[1]\n",
    "print(prediction.shape)\n",
    "combined_prediction = get_combined_mask(prediction)\n",
    "concat_prediction = torch.flatten(combined_prediction)\n",
    "\n",
    "print(concat_prediction.shape)\n",
    "\n",
    "one_pred_labels = concat_prediction[concat_labels == 1]\n",
    "two_pred_labels = concat_prediction[concat_labels == 2]\n",
    "# zero_pred_labels= concat_prediction[concat_labels == 0]\n",
    "\n",
    "# print(zero_pred_labels.shape)\n",
    "\n",
    "pred_labels_plot = torch.cat((one_pred_labels, \n",
    "                              two_pred_labels, \n",
    "                            #   zero_pred_labels\n",
    "                              ), 0)\n",
    "\n",
    "print(\"Equality : \" , pred_labels_plot == concat_labels_plot)\n",
    "# show_tsne_plot(tsne_output.transpose(0,1), pred_labels_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try checking out prototypes\n",
    "prototypes = None\n",
    "bias = None\n",
    "for name, p in model.named_parameters():\n",
    "    if 'decoder.last_conv.3.weight' in name:\n",
    "        prototypes = p\n",
    "    if 'decoder.last_conv.3.bias' in name:\n",
    "        bias = p\n",
    "\n",
    "for name, p in model_noada.named_parameters():\n",
    "    if 'decoder.last_conv.3.weight' in name:\n",
    "        prototypes_noada = p\n",
    "    if 'decoder.last_conv.3.bias' in name:\n",
    "        bias_noada = p\n",
    "\n",
    "\n",
    "print(prototypes.shape)\n",
    "print(reduced_feats.shape)\n",
    "\n",
    "\n",
    "# Note - might need to take bias into account !\n",
    "prototypes = (prototypes - prototypes.mean()) / prototypes.std()\n",
    "class_0_prototypes = prototypes[0,:,0,0]\n",
    "class_1_prototypes = prototypes[1,:,0,0]\n",
    "\n",
    "prototypes_noada = (prototypes_noada - prototypes_noada.mean()) / prototypes_noada.std()\n",
    "class_0_prototypes_noada = prototypes_noada[0,:,0,0]\n",
    "class_1_prototypes_noada = prototypes_noada[1,:,0,0]\n",
    "\n",
    "print(f\"bias shape {bias.shape}\")\n",
    "print(bias)\n",
    "print(class_0_prototypes.shape)\n",
    "print(class_1_prototypes.shape)\n",
    "\n",
    "print(class_0_prototypes[:10])\n",
    "print(class_1_prototypes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(one_feats.shape)\n",
    "reduced_feats = torch.cat((one_feats, two_feats, \n",
    "                        #    zero_feats\n",
    "                           ), 1)\n",
    "\n",
    "#normalize\n",
    "reduced_feats = (reduced_feats - reduced_feats.mean()) / reduced_feats.std()\n",
    "\n",
    "print(reduced_feats.shape)\n",
    "print(class_0_prototypes.unsqueeze(1).shape)\n",
    "reduced_feats_noada = torch.cat((reduced_feats, class_0_prototypes_noada.unsqueeze(1), class_1_prototypes_noada.unsqueeze(1)), 1)\n",
    "\n",
    "reduced_feats = torch.cat((reduced_feats, class_0_prototypes.unsqueeze(1), class_1_prototypes.unsqueeze(1)), 1)\n",
    "\n",
    "\n",
    "print(one_feats.shape)\n",
    "print(two_feats.shape)\n",
    "print(reduced_feats.shape)\n",
    "print(tsne_feats.shape)\n",
    "\n",
    "print(class_0_prototypes.shape)\n",
    "\n",
    "\n",
    "tsne_output = compute_tsne(reduced_feats.cpu().detach().transpose(0,1).numpy())\n",
    "tsne_output_noada = compute_tsne(reduced_feats_noada.cpu().detach().transpose(0,1).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsne_output.shape)\n",
    "print(tsne_output_noada.shape)\n",
    "# concat_labels = [1]*1500 + [2]*1500 + [0]*1500 + [1]*1 + [2] * 1\n",
    "print((pred_labels_plot == 0).sum())\n",
    "concat_labels_plot_proto = concat_labels_plot + [0,1]\n",
    "pred_labels_plot_proto = list(pred_labels_plot) + [0, 1]\n",
    "\n",
    "\n",
    "\n",
    "print(\"**** AFTER DPL *****\")\n",
    "print(\"pred\")\n",
    "show_tsne_plot(tsne_output.transpose(0,1), pred_labels_plot_proto, num_prototypes=2)\n",
    "print(\"gt\")\n",
    "show_tsne_plot(tsne_output.transpose(0,1), concat_labels_plot_proto, num_prototypes=2)\n",
    "\n",
    "print(\"**** NOADA *****\")\n",
    "print(\"pred\")\n",
    "show_tsne_plot(tsne_output_noada.transpose(0,1), pred_labels_plot_proto, num_prototypes=2)\n",
    "print(\"gt)\")\n",
    "show_tsne_plot(tsne_output_noada.transpose(0,1), concat_labels_plot_proto, num_prototypes=2)\n",
    "\n",
    "# print(tsne_output[-1])\n",
    "# print(tsne_output[-2])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
